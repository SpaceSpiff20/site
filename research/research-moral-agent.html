<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Daniel Grossman | Research</title>
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link
        href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600&family=Playfair+Display:ital,wght@0,400;0,700;1,400&display=swap"
        rel="stylesheet">
    <link rel="stylesheet" href="../style.css">
</head>

<body>
    <header>
        <h1>Daniel Grossman</h1>
        <nav>
            <ul>
                <li><a href="../index.html">Home</a></li>
                <li><a href="../about.html">About</a></li>
                <li><a href="../experiences.html">Work Experience</a></li>
                <li><a href="../research.html" class="active">Research</a></li>
                <li><a href="../projects.html">Projects</a></li>
                <li><a href="../contact.html">Contact</a></li>
            </ul>
        </nav>
    </header>

    <main>
        <a href="../research.html" class="btn" style="margin-bottom: 2rem; padding: 10px 20px; font-size: 0.8rem;">←
            Back
            to Research</a>

        <article class="card" style="cursor: default; transform: none; box-shadow: none;">
            <h2 class="section-title">"How to Make a Moral Agent"</h2>
            <div class="date-location">
                <span>Researcher and Author</span>
                <span>Stanford, CA | April 2025 – June 2025</span>
            </div>

            <div style="margin-top: 2rem; font-size: 1.05rem; line-height: 1.8; color: #444;">
                <p style="margin-bottom: 1.5rem;">
                    <strong>Abstract:</strong><br>
                    This research explores the emergence of trust and cooperation among Large Language Model (LLM)
                    agents within iterated Prisoner's Dilemma (IPD) scenarios. The central insight emerged from the
                    critical experimental distinction between agents assuming repeated interactions with the same
                    partners versus having knowledge of random pairing. Findings illustrate that cooperative behavior
                    and trust depend fundamentally upon the agents' capability for partner selection and ongoing
                    repeated interactions. When agents lacked partner choice, cooperative strategies were quickly
                    abandoned, leading to aggressive dominance and eventual population collapse. These results may
                    inform debates between computational ethics and moral cognition in artificial intelligence,
                    emphasizing partner selection as essential for moral cognition approaches.
                </p>

                <p style="margin-bottom: 1.5rem;">
                    <strong>Key Focus Areas:</strong>
                </p>
                <ul class="details" style="margin-left: 1rem; list-style-type: disc; padding-left: 1rem;">
                    <li> Partner selection and the maintenance of repeated interactions are fundamental to the emergence
                        of trust and cooperative norms among LLM agents. </li>
                    <li> Cooperative strategies fail, and aggressive strategies dominate when agents cannot select or
                        maintain chosen partners, as shown in Condition B where population runs crashed to extinction.
                    </li>
                    <li> The findings suggest that to develop truly moral agents, researchers should move beyond
                        hard-coded ethical rules and instead engineer environments where selection pressures favor
                        cooperation through choice, memory, and reputation. </li>
                </ul>

                <div style="margin-top: 3rem; padding-top: 2rem; border-top: 1px solid #eee;">
                    <h3>Read the Paper</h3>
                    <p>
                        <a href="https://drive.google.com/file/d/1_pMh3g1nylpgp3ZdYeU7psqskUhbAPrH/view?usp=sharing"
                            target="_blank" rel="noopener noreferrer">View
                            Report</a>
                    </p>
                </div>
            </div>
        </article>
    </main>

    <footer>
        <p>&copy; 2025 Daniel Grossman. All rights reserved.</p>
    </footer>
</body>

</html>